#!/usr/bin/env python3
# coding: utf-8

"""
Creatore di Digest Bot
- –ü—Ä–∏–Ω–∏–º–∞–µ—Ç Excel-—Ñ–∞–π–ª (–∏–º—è –∫–∞–Ω–∞–ª–∞ | –∞–¥—Ä–µ—Å/username)
- –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª: —Å—É—Ç–∫–∏/–Ω–µ–¥–µ–ª—è/–º–µ—Å—è—Ü/–ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π
- –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ / —Ç–µ–≥–∏
- –°–∫–∞—á–∏–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–∞–Ω–∞–ª–æ–≤ (—á–µ—Ä–µ–∑ Telethon –∏–ª–∏ Bot API –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
- –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –∫–ª—é—á–∞–º, —Å—É–º–º–∞—Ä–∏–∑—É–µ—Ç (NLTK), —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç .docx
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø—Ü–∏—é –∞–≤—Ç–æ–¥–æ—Å—Ç–∞–≤–∫–∏ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é (apscheduler)
- –ö–µ—à–∏—Ä—É–µ—Ç —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ sqlite
"""

import os
import logging
import tempfile
import sqlite3
import asyncio
import html
from datetime import datetime, timedelta
from io import BytesIO
from typing import List, Tuple, Optional

import pandas as pd
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from docx import Document

from apscheduler.schedulers.asyncio import AsyncIOScheduler

from telethon import TelegramClient, errors as telethon_errors
from telethon.tl.types import PeerChannel

from telegram import (
    Update, 
    InlineKeyboardButton, 
    InlineKeyboardMarkup, 
    ReplyKeyboardRemove,
    KeyboardButton, 
    ReplyKeyboardMarkup, 
    InputFile
)
from telegram.ext import (
    Application,
    ApplicationBuilder, 
    CommandHandler, 
    MessageHandler, 
    CallbackQueryHandler, 
    ContextTypes,
    filters,
    ConversationHandler
)

# -----------------------------
# –ö–æ–Ω—Ñ–∏–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
# -----------------------------
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# -----------------------------
# –°–æ—Å—Ç–æ—è–Ω–∏—è
# -----------------------------
WAITING_FOR_FILE = 1
WAITING_FOR_INTERVAL = 2
WAITING_FOR_CUSTOM_INTERVAL_FROM = 3
WAITING_FOR_CUSTOM_INTERVAL_TO = 4
WAITING_FOR_KEYWORDS = 5

# NLTK setup (–±—É–¥–µ—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)
nltk_resources = ["punkt", "stopwords"]
for res in nltk_resources:
    try:
        nltk.data.find(res)
    except LookupError:
        nltk.download(res)

STOPWORDS = set(stopwords.words("russian")) | set(stopwords.words("english"))
STEMMER = SnowballStemmer("russian")

# -----------------------------
# –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤
# -----------------------------
def get_secret(name: str, docker_secret_path: Optional[str] = None) -> Optional[str]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–∞:
    - –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–ºc—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å Docker secret (–ø–æ –ø—É—Ç–∏ /run/secrets/<name>), –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    - –ò–Ω–∞—á–µ –±–µ—Ä–µ–º –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    """
    # Docker secrets location (standard)
    secret_file = f"/run/secrets/{name}"
    if os.path.exists(secret_file):
        with open(secret_file, "r") as f:
            return f.read().strip()
    # fallback to env
    return os.getenv(name)

def get_telegram_token() -> str:
    token = get_secret("TELEGRAM_BOT_TOKEN")
    if not token:
        raise RuntimeError("TELEGRAM_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ –∏–ª–∏ Docker Secret.")
    return token

def get_telethon_credentials() -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (api_id, api_hash, session_string).
    –ï—Å–ª–∏ api_id/api_hash –∑–∞–¥–∞–Ω—ã, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Telethon –¥–ª—è —á—Ç–µ–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤.
    –ï—Å–ª–∏ session_string –∑–∞–¥–∞–Ω—ã ‚Äî Telethon –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö.
    """
    api_id = get_secret("TELETHON_API_ID")
    api_hash = get_secret("TELETHON_API_HASH")
    session = get_secret("TELETHON_SESSION")  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    return api_id, api_hash, session

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
client = TelegramClient('session_name', int(API_ID), API_HASH)

# -----------------------------
# –ü—Ä–æ—Å—Ç–æ–π SQLite –∫–µ—à –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π
# -----------------------------
# –ü—É—Ç—å –∫ –±–∞–∑–µ –±–µ—Ä—ë–º –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç
DB_PATH = os.getenv("DB_PATH", "/app/data/digest_cache.sqlite")

def init_db():
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)  # —Å–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS digests (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            channel_name TEXT,
            channel_link TEXT,
            content TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.commit()
    conn.close()

def cache_posts(posts: List[Tuple[str,str,str,str]]):
    """
    posts: list of tuples (id, channel, date_iso, text)
    """
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    for pid, channel, date_iso, text in posts:
        try:
            cur.execute("INSERT OR IGNORE INTO posts (id, channel, date, text) VALUES (?, ?, ?, ?)",
                        (pid, channel, date_iso, text))
        except Exception as e:
            logger.exception("DB insert failed: %s", e)
    conn.commit()
    conn.close()

def query_posts(channel: str, date_from: datetime, date_to: datetime) -> List[Tuple[str,str,str,str]]:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT id, channel, date, text FROM posts WHERE channel=? AND date BETWEEN ? AND ?",
                (channel, date_from.isoformat(), date_to.isoformat()))
    rows = cur.fetchall()
    conn.close()
    return rows

# -----------------------------
# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (–Ω–∞ –±–∞–∑–µ NLTK)
# -----------------------------
def normalize_word(w: str) -> str:
    w = w.lower()
    w = ''.join(ch for ch in w if ch.isalpha() or ch == '-')
    if not w: 
        return w
    try:
        return STEMMER.stem(w)
    except Exception:
        return w

def text_score_sentences(text: str, keywords: List[str], top_n_sentences: int = 3) -> List[str]:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è: —Å—Ä–µ–¥–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤—ã–±–∏—Ä–∞–µ–º top_n –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    –∏–ª–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤.
    """
    if not text or text.strip() == "":
        return []
    sents = sent_tokenize(text)
    if not sents:
        return []
    # build keyword set
    kw_norm = set(normalize_word(k) for k in keywords if k.strip())
    # score each sentence
    scores = []
    for s in sents:
        words = [normalize_word(w) for w in word_tokenize(s)]
        # keyword hits
        hits = sum(1 for w in words if w in kw_norm)
        # informative score: number of non-stopword tokens
        informative = sum(1 for w in words if w and w not in STOPWORDS)
        total = hits * 5 + informative  # bias keywords
        scores.append((total, s))
    # sort
    scores.sort(key=lambda x: x[0], reverse=True)
    chosen = [s for _, s in scores[:top_n_sentences]]
    # If keywords empty and no hits, fall back to first N sentences
    if not chosen:
        chosen = sents[:top_n_sentences]
    # deduplicate and preserve order appearing in original
    chosen_set = set(chosen)
    final = [s for s in sents if s in chosen_set]
    return final[:top_n_sentences]

# -----------------------------
# Telethon client helper
# -----------------------------
async def fetch_messages_telethon(api_id: str, api_hash: str, session: Optional[str], channel_username: str,
                                  date_from: datetime, date_to: datetime, limit: int = 200) -> List[Tuple[str,str,str,str]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ Telethon (user client).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (id, channel_username, date_iso, text)
    """
    # Session: –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–∞ —Å—Ç—Ä–æ–∫–∞ ‚Äî –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–µ –∫–∞–∫ session name
    session_name = session or "digest_bot_session"
    client = TelegramClient(session_name, int(api_id), api_hash)
    await client.start()
    posts = []
    try:
        # resolve entity
        try:
            entity = await client.get_entity(channel_username)
        except Exception:
            # last resort: try to get by username as PeerChannel (some public channels)
            raise

        # iterate messages in date range
        async for msg in client.iter_messages(entity, limit=limit, reverse=False):
            if not msg.date:
                continue
            if msg.date.replace(tzinfo=None) < date_from:
                continue
            if msg.date.replace(tzinfo=None) > date_to:
                continue
            text = msg.message or ""
            pid = f"{entity.id}_{msg.id}"
            posts.append((pid, channel_username, msg.date.isoformat(), text))
    except telethon_errors.rpcerrorlist.ChannelPrivateError:
        logger.warning("Channel %s is private or access denied.", channel_username)
    except Exception as e:
        logger.exception("Telethon fetch error for %s: %s", channel_username, e)
    finally:
        await client.disconnect()
    return posts

# -----------------------------
# –§–æ–ª–ª–±–µ–∫: –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ Bot API (–µ—Å–ª–∏ –±–æ—Ç –∞–¥–º–∏–Ω –∫–∞–Ω–∞–ª–∞)
# -----------------------------
# NOTE: Telegram Bot API generally –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø—É–±–ª–∏—á–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤,
# –µ—Å–ª–∏ –±–æ—Ç –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –∏ –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –±–æ—Ç —è–≤–ª—è–µ—Ç—Å—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º/–∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø.
# –í python-telegram-bot –µ—Å—Ç—å –º–µ—Ç–æ–¥ get_chat –∏ get_chat_history –≤ —Ñ–æ—Ä–º–µ get_updates? –í v20 Bot API –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä—è–º–æ–π fetch history,
# –ø–æ—ç—Ç–æ–º—É –º—ã –æ—Å—Ç–∞–≤–∏–º —ç—Ç–æ –∫–∞–∫ stub / placeholder –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Telethon.
async def fetch_messages_botapi_stub(application, chat_identifier: str, date_from: datetime, date_to: datetime):
    # stub: –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π
    logger.info("Bot API fetch stub called for %s ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Telethon (user API) –∏–ª–∏ —Å–¥–µ–ª–∞—Ç—å –±–æ—Ç–∞ –∞–¥–º–∏–Ω–æ–º –∫–∞–Ω–∞–ª–æ–≤.", chat_identifier)
    return []

# -----------------------------
# –°–æ–∑–¥–∞–Ω–∏–µ .docx —Å –¥–∞–π–¥–∂–µ—Å—Ç–æ–º
# -----------------------------
def create_docx_digest(digest_entries: List[Tuple[str, str, str, List[str]]], title: str = "–î–∞–π–¥–∂–µ—Å—Ç") -> bytes:
    """
    digest_entries: list of tuples (channel_name, channel_link, post_date_iso, summary_sentences_list)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes docx
    """
    doc = Document()
    doc.add_heading(title, level=1)
    doc.add_paragraph(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.utcnow().isoformat()} UTC")
    for channel, link, date_iso, summary_sentences in digest_entries:
        p = doc.add_paragraph()
        p.add_run(channel).bold = True
        if link:
            p.add_run(f" ‚Äî {link}")
        p.add_run(f" ({date_iso})\n")
        for sent in summary_sentences:
            doc.add_paragraph(sent, style='List Bullet')
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.read()

# -----------------------------
# –õ–æ–≥–∏–∫–∞ –±–æ—Ç–∞ / Handlers
# -----------------------------
# We'll keep a simple in-memory per-chat state (single-user assumption)
CHAT_STATE = {}

def reset_chat_state(chat_id: int):
    CHAT_STATE[chat_id] = {
        "excel_path": None,
        "channels_df": None,
        "interval": None,
        "date_from": None,
        "date_to": None,
        "keywords": [],
        "use_telethon": False
    }

# Helpers to parse interval choice
def parse_interval_choice(choice: str) -> Tuple[datetime, datetime]:
    now = datetime.utcnow()
    if choice == "–°—É—Ç–∫–∏":
        return now - timedelta(days=1), now
    elif choice == "–ù–µ–¥–µ–ª—è":
        return now - timedelta(weeks=1), now
    elif choice == "–ú–µ—Å—è—Ü":
        return now - timedelta(days=30), now
    else:
        raise ValueError("unsupported quick choice")

# Build interval keyboard
def interval_keyboard():
    keyboard = [
        [InlineKeyboardButton("–°—É—Ç–∫–∏", callback_data="interval_–°—É—Ç–∫–∏"),
         InlineKeyboardButton("–ù–µ–¥–µ–ª—è", callback_data="interval_–ù–µ–¥–µ–ª—è")],
        [InlineKeyboardButton("–ú–µ—Å—è—Ü", callback_data="interval_–ú–µ—Å—è—Ü"),
         InlineKeyboardButton("–ó–∞–¥–∞–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª", callback_data="interval_custom")]
    ]
    return InlineKeyboardMarkup(keyboard)

# Start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    reset_chat_state(chat_id)
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ Excel-—Ñ–∞–π–ª (xlsx) —Å–æ —Å–ø–∏—Å–∫–æ–º –∫–∞–Ω–∞–ª–æ–≤ (—Å—Ç–æ–ª–±—Ü—ã: –∏–º—è –∫–∞–Ω–∞–ª–∞, –∞–¥—Ä–µ—Å/username).\n"
        "–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 2 —Å—Ç–æ–ª–±—Ü–∞: 'name' –∏ 'address' (–∏–ª–∏ –ø–µ—Ä–≤—ã–µ –¥–≤–∞ —Å—Ç–æ–ª–±—Ü–∞ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã)."
    )
    return WAITING_FOR_FILE

# -----------------------------
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
# -----------------------------
async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    document = update.message.document

    if not document:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª.")
        return WAITING_FOR_FILE

    with tempfile.NamedTemporaryFile(delete=False) as tf:
        tg_file = await document.get_file()
        await tg_file.download_to_drive(tf.name)
        file_path = tf.name

    ext = os.path.splitext(document.file_name)[-1].lower()
    try:
        if ext == ".xlsx":
            df = pd.read_excel(file_path, engine="openpyxl")
        elif ext == ".xls":
            df = pd.read_excel(file_path, engine="xlrd")
        else:
            await update.message.reply_text("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ .xls –∏–ª–∏ .xlsx")
            return WAITING_FOR_FILE
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ Excel: {e}")
        return WAITING_FOR_FILE
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—É –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    context.user_data["channels"] = df

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –≤—ã–±–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    keyboard = [
        [InlineKeyboardButton("–°—É—Ç–∫–∏", callback_data="interval_day")],
        [InlineKeyboardButton("–ù–µ–¥–µ–ª—è", callback_data="interval_week")],
        [InlineKeyboardButton("–ú–µ—Å—è—Ü", callback_data="interval_month")],
        [InlineKeyboardButton("–ó–∞–¥–∞–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª", callback_data="interval_custom")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤—Ä–µ–º–µ–Ω–∏:", reply_markup=reply_markup)

    return WAITING_FOR_INTERVAL

async def handle_interval(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()

    if text in ["–°—É—Ç–∫–∏", "–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"]:
        context.user_data["interval"] = text
        await update.message.reply_text(
            f"‚è≥ –í—ã –≤—ã–±—Ä–∞–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª: {text}\n\n–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–ª–∏ —Ç–µ–≥–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
            reply_markup=ReplyKeyboardRemove()
        )
    elif text == "–ó–∞–¥–∞–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª":
        context.user_data["interval"] = "custom"
        await update.message.reply_text(
            "‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ: `YYYY-MM-DD –¥–æ YYYY-MM-DD`",
            parse_mode="Markdown",
            reply_markup=ReplyKeyboardRemove()
        )
    else:
        await update.message.reply_text("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤.")

# -----------------------------
# Callback –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
# -----------------------------
async def interval_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    data = query.data.replace("interval_", "")

    if data == "custom":
        await query.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (–ì–ì–ì–ì-–ú–ú-–î–î):")
        return WAITING_FOR_CUSTOM_INTERVAL_FROM
    else:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
        context.user_data["interval"] = data
        await query.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):")
        return WAITING_FOR_KEYWORDS

# -----------------------------
# –ö–∞—Å—Ç–æ–º–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: –Ω–∞—á–∞–ª–æ
# -----------------------------
async def custom_interval_from(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["custom_from"] = update.message.text.strip()
    await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (–ì–ì–ì–ì-–ú–ú-–î–î):")
    return WAITING_FOR_CUSTOM_INTERVAL_TO

# -----------------------------
# –ö–∞—Å—Ç–æ–º–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: –∫–æ–Ω–µ—Ü
# -----------------------------
async def custom_interval_to(update: Update, context: ContextTypes.DEFAULT_TYPE):
    custom_from = context.user_data.get("custom_from")
    custom_to = update.message.text.strip()
    context.user_data["interval"] = (custom_from, custom_to)

    await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):")
    return WAITING_FOR_KEYWORDS

# -----------------------------
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
# -----------------------------
async def handle_keywords(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keywords = [k.strip() for k in update.message.text.split(",") if k.strip()]
    context.user_data["keywords"] = keywords

    await update.message.reply_text(
        "–§–∞–π–ª –ø—Ä–∏–Ω—è—Ç ‚úÖ\n–ò–Ω—Ç–µ—Ä–≤–∞–ª –∑–∞–¥–∞–Ω ‚úÖ\n–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã ‚úÖ\n\n–ì–æ—Ç–æ–≤–ª—é –¥–∞–π–¥–∂–µ—Å—Ç...",
        reply_markup=ReplyKeyboardRemove()
    )

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º generate_digest
    digest_path = await generate_digest(context.user_data)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º await –∑–¥–µ—Å—å

    if digest_path and os.path.exists(digest_path):
        await update.message.reply_document(open(digest_path, "rb"), filename="digest.docx")
    else:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç üò¢")

    return ConversationHandler.END

async def get_posts(channel_link, interval):
    await client.start()
    channel = await client.get_entity(channel_link)
    now = datetime.utcnow()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    if interval == "day":
        start_date = now - timedelta(days=1)
    elif interval == "week":
        start_date = now - timedelta(weeks=1)
    elif interval == "month":
        start_date = now - timedelta(days=30)
    elif isinstance(interval, tuple):
        start_date = datetime.fromisoformat(interval[0])
        end_date = datetime.fromisoformat(interval[1])
    else:
        start_date = now - timedelta(days=1)
    end_date = now if not isinstance(interval, tuple) else end_date

    posts_text = []
    async for message in client.iter_messages(channel, offset_date=end_date, reverse=True):
        if message.date < start_date:
            break
        if message.text:
            posts_text.append((message.date, message.text))
        else:
            print(f"Message without text found: {message.date}")
    
    print(f"Found {len(posts_text)} posts in channel: {channel_link}")
    return posts_text

async def generate_digest(user_data):
    channels = user_data.get("channels")
    interval = user_data.get("interval")
    keywords = user_data.get("keywords", [])

    if channels is None or not keywords:
        return None

    await client.start()

    digest_text = "üìå –î–∞–π–¥–∂–µ—Å—Ç –ø–æ –≤–∞—à–∏–º –∫–∞–Ω–∞–ª–∞–º:\n\n"

    for _, row in channels.iterrows():
        channel_name = row[0]
        channel_link = row[1]

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç—ã
        posts = await get_posts(channel_link, interval)
        if not posts:
            digest_text += f"{channel_name} ({channel_link}): –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ —ç—Ç–æ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª\n"
            continue
        
        digest_text += f"--- {channel_name} ({channel_link}) ---\n"
        for date, text in posts:
            if text:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π
                summary = summarize_text(text, keywords)
                digest_text += f"{date.date()}: {summary}\n"
            else:
                digest_text += f"{date.date()}: (–ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ)\n"

    output_dir = "/app/data"
    os.makedirs(output_dir, exist_ok=True)
    digest_path = os.path.join(output_dir, "digest.docx")

    doc = Document()
    doc.add_heading("–î–∞–π–¥–∂–µ—Å—Ç", 0)
    doc.add_paragraph(digest_text)
    doc.save(digest_path)

    return digest_path

# Core processing
async def process_digest_for_chat(chat_id: int, context: ContextTypes.DEFAULT_TYPE):
    state = CHAT_STATE.get(chat_id)
    if not state:
        await context.bot.send_message(chat_id, "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /start.")
        return

    df: pd.DataFrame = state.get("channels_df")
    date_from: datetime = state.get("date_from")
    date_to: datetime = state.get("date_to")
    keywords: List[str] = state.get("keywords", [])

    if df is None or date_from is None or date_to is None:
        await context.bot.send_message(chat_id, "–ù–µ—á–µ–≥–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∑–∞–Ω–æ–≤–æ /start.")
        return

    await context.bot.send_message(chat_id, f"–°–æ–±–∏—Ä–∞—é –ø–æ—Å—Ç—ã –∏–∑ {len(df)} –∫–∞–Ω–∞–ª–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥ {date_from.date()} ‚Äî {date_to.date()}...")

    # choose Telethon if configured
    api_id, api_hash, session = get_telethon_credentials()
    use_telethon = False
    if api_id and api_hash:
        use_telethon = True

    collected_posts = []  # list of (id, channel, date_iso, text)
    # iterate channels
    for idx, row in df.iterrows():
        chan_name = str(row['name'])
        chan_addr = str(row['address'])
        try:
            if use_telethon:
                try:
                    posts = await fetch_messages_telethon(api_id, api_hash, session, chan_addr, date_from, date_to, limit=500)
                except Exception as e:
                    logger.exception("Telethon per-channel error: %s", e)
                    posts = []
            else:
                posts = await fetch_messages_botapi_stub(context.application, chan_addr, date_from, date_to)
            # if posts empty - try cached posts
            if not posts:
                cached = query_posts(chan_addr, date_from, date_to)
                if cached:
                    posts = cached
            if posts:
                collected_posts.extend(posts)
                cache_posts(posts)
        except Exception as e:
            logger.exception("Error fetching channel %s: %s", chan_addr, e)

    if not collected_posts:
        await context.bot.send_message(chat_id, "–ó–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –ø–æ—Å—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    await context.bot.send_message(chat_id, f"–ù–∞–π–¥–µ–Ω–æ {len(collected_posts)} –ø–æ—Å—Ç–æ–≤. –í—ã–ø–æ–ª–Ω—è—é —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é...")

    # Group posts by channel and date, make summaries
    digest_entries = []
    grouped = {}
    for pid, channel, date_iso, text in collected_posts:
        key = (channel, date_iso[:10])  # group by date (YYYY-MM-DD)
        grouped.setdefault(key, []).append(text or "")

    # For each group produce summary
    for (channel, date_only), texts in grouped.items():
        combined_text = "\n".join(texts)
        # our summarizer: get top sentences
        top_sents = text_score_sentences(combined_text, keywords, top_n_sentences=4)
        # create link if channel looks like @username or t.me/...
        link = None
        if channel.startswith("@"):
            link = f"https://t.me/{channel[1:]}"
        elif channel.startswith("http"):
            link = channel
        else:
            # try direct t.me
            link = f"https://t.me/{channel}"
        digest_entries.append((channel, link, date_only, top_sents))

    # Create docx
    docx_bytes = create_docx_digest(digest_entries, title=f"–î–∞–π–¥–∂–µ—Å—Ç {date_from.date()} ‚Äî {date_to.date()}")
    await context.bot.send_document(chat_id, document=InputFile(BytesIO(docx_bytes), filename=f"digest_{date_from.date()}_{date_to.date()}.docx"))
    await context.bot.send_message(chat_id, "–î–∞–π–¥–∂–µ—Å—Ç –≥–æ—Ç–æ–≤ –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω. –°–ø–∞—Å–∏–±–æ!")

# Command to schedule regular digest (optional improvement)
async def schedule_digest_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    # This is a simple example that schedules every day at 09:00 UTC
    await update.message.reply_text("–ó–∞–ø—Ä–æ—à–µ–Ω–æ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –≤ 09:00 UTC. (–ü—Ä–∏–º–µ—Ä)")
    scheduler = context.bot_data.get("scheduler")
    if not scheduler:
        scheduler = AsyncIOScheduler()
        scheduler.start()
        context.bot_data["scheduler"] = scheduler

    async def job_fn():
        # For simplicity, use existing chat state
        await process_digest_for_chat(chat_id, context)

    scheduler.add_job(job_fn, 'cron', hour=9, minute=0, id=f"digest_{chat_id}", replace_existing=True)
    await update.message.reply_text("–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∞ (09:00 UTC).")

# Cancel
async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    reset_chat_state(chat_id)
    await update.message.reply_text("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ, –Ω–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ /start.")
    return ConversationHandler.END

# Fallback unknown messages
async def unknown(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ù–µ –ø–æ–Ω—è–ª. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª Excel —Å –∫–∞–Ω–∞–ª–∞–º–∏.")

# -----------------------------
# Main
# -----------------------------
def main():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    init_db()

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –±–æ—Ç–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ
    token = get_telegram_token()

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = ApplicationBuilder().token(token).build()

    # ConversationHandler –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],

        states={
            WAITING_FOR_FILE: [
                MessageHandler(filters.Document.ALL, handle_file)
            ],
            WAITING_FOR_INTERVAL: [
                CallbackQueryHandler(interval_callback, pattern=r"^interval_")
            ],
            WAITING_FOR_CUSTOM_INTERVAL_FROM: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, custom_interval_from)
            ],
            WAITING_FOR_CUSTOM_INTERVAL_TO: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, custom_interval_to)
            ],
            WAITING_FOR_KEYWORDS: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_keywords)
            ]
        },

        fallbacks=[CommandHandler("cancel", cancel)]
    )

    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤
    application.add_handler(conv_handler)
    application.add_handler(CommandHandler("schedule", schedule_digest_cmd))
    application.add_handler(MessageHandler(filters.COMMAND, unknown))  # –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

    # –°—Ç–∞—Ä—Ç –±–æ—Ç–∞
    logger.info("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()


# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
if __name__ == "__main__":
    main()